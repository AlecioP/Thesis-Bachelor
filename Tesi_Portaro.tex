\documentclass[12pt,a4paper,fleqn]{report}

%Packages :
\usepackage[utf8]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=3.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{graphicx}
%For using biblatex and babel packages at the same time
\usepackage{csquotes}
\usepackage[style=ieee,useprefix,citestyle=numeric-comp,backend=bibtex]{biblatex}
\bibliography{reference.bib}

\usepackage{tabularx}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{xcolor} % for setting colors
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\graphicspath{ {immagini/} }


% set the default code style
\lstset{
    frame=tb, % draw a frame at the top and bottom of the code block
    tabsize=4, % tab space width
    showstringspaces=false, % don't mark spaces in strings
    numbers=left, % display line numbers on the left
    basicstyle=\footnotesize\ttfamily,% basic font setting
    columns=fullflexible,
    commentstyle=\color{green}, % comment color
    keywordstyle=\color{blue}, % keyword color
    stringstyle=\color{red} % string color
}
%For the quotes paragraphs
\usepackage{etoolbox}
\AtBeginEnvironment{quote}{\singlespacing\small}
%dependency
\usepackage{setspace}

%For pseudocode 
\usepackage{algorithm}
\usepackage[noend]{algorithmic}

%For c++ code

\usepackage{listings}
\usepackage{color}

%Bold math symbols 

\usepackage{bm}
\newcommand\bolden[1]{{\boldmath\bfseries#1}}

%url

\usepackage{url}

%math symbols +

\usepackage{mathabx}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%TITLE PAGE
\begin{titlepage}
\begin{center}
\huge{\textbf{University of Calabria}}\\
\begin{figure}[bt]
\centering
\includegraphics[scale=0.5]{Stemma}\\
\end{figure}
\line(1,0){400}\\[5mm]
\Large{\textbf{Department of Mathematics and Computer Science}}\\
\Large{\textbf{Bachelor's Degree in Computer Science}}\\
\vspace{35mm}
\Huge{\textbf{Application of Distributed Discrete-Event Simulation Techniques in Parallel Execution of Cellular Automata}}
\end{center}
\vspace{35mm}
\begin{flushleft}
\large{\textsc{\textit{\textbf{ADVISOR}}}}
\hfill \large{\textit{\textsc{\textbf{EXAMINEE}}}}\\
\Large{\textit{Prof. William Spataro}}
\hfill \Large{\textit{Alessio Portaro}}\\
\Large{\textit{Prof. Donato D'Ambrosio}}
\hfill \Large{\textit{176231}}\\
\large{\textsc{\textit{\textbf{CO-ADVISOR}}}}\\
\Large{\textit{Eng. Andrea Giordano}}
\end{flushleft}
\vfill
\begin{center}
\line(1,0){430}\\[5mm]
{\large{\bf Academic Year 2018/2019}}\\
\end{center}
\end{titlepage}
%TITLE PAGE END
\newpage
\thispagestyle{empty}
\tableofcontents
\thispagestyle{empty}

\newpage
\setcounter{page}{1}
\chapter{Introduction}
%As suggested from the title, this thesis' main aim is to examine in depth some aspects of \textit{Cellular Automata} that may result in overhead reduction and performances improvements, when this kind of simulation is executed in a Parallel and Distributed Environment. Most specifically our focus will be on the notion of \textit{Idle Cell}, well known in CA's literature. Latter is strictly related with another concept, coming from Discrete-event Distributed and Parallel Simulation 
Nowadays, many entities operating in several fields, require some software or hardware utility to improve the results of their work. Among these utilities, some of the most interesting are the so-called \textit{Simulation Systems}, namely software frameworks, more or less complex, useful to handle and process great amount of data, concerning the same simulated model. Between the various applications, the followings are the most relevant ones :
\begin{enumerate}
\item
\textbf{Military simulators}, used to improve the effectiveness of the recruit's training. For instance there are many fly simulators to supplement the drills of pilots, or simulators to train soldier's strategy talent, which submit them battle scenarios and handle the evolution of the simulation starting from the soldier's answers.
\item
\textbf{Infrastructures simulators}, developed in order to monitor the behavior of some new technology or infrastructure's component. For example one could simulate the usage of a new communication protocol, or the impact, over a road network's traffic, of building a new transport highway.
\item
\textbf{Scientific simulations} are systems developed ad hoc to collect data in favour of some new theory or monitor the possible effects of a physical phenomenon, by the simulation of a model approximating its properties. I.e. in the next chapters of this treatise, it will be depicted a model which simulates the evolution of a landslide, by the simulation paradigm of a\\ \textbf{Cellular Automaton} : \textit{SciddicaT}.
\item
\textbf{Entertainment Industry }. In this field there are several applications and many others are to come, because of the great interest raised and all the heavy investments. One example that stands out among the others are the \textit{Augmented reality} platforms.
\end{enumerate}
 
The main categorization of the \textit{Simulation Systems} is in two opposite types, differing in the way the time flowing is modeled :
\begin{itemize}
\item
\textbf{Discrete-event simulation}, is a paradigm where the state of the simulation instantly evolves at certain points in time, while maintains its internal state between each couple of transition instants.
\item
\textbf{Continuous time simulation}, on the contrary is a paradigm where the simulation's state is supposed to change continuously during the time. The association between the state of the system and a point in the simulation time is kept via a mathematical function.
\end{itemize}
Both types of simulation are strongly related to the concept of time and the way the abstraction of the this last evolves during the system's evolution. In particular, in the case of the \textit{Discrete-event simulation}, which is the one we discuss in this thesis, there can be differentiated two main execution types, in accordance with the different ways the abstraction of the time evolves :
\begin{itemize}
\item
\textbf{Event-Driven execution} : When this paradigm of execution is adopted, the state of the system only changes when an event occurs, that's to say when an action would occur in the real system. Each event has to bear an unique time reference and usually affects the internal state of the system, generating new events itself. Whenever possible, this paradigm can be convenient because the simulator maybe doesn't perform useless operations, but could lead to a performance reduction in \textbf{as soon as possible} simulations.
\item
\textbf{Time-stepped execution} : This paradigm is characterized by the contemporary evolution of the system state and the time abstraction. The system makes the state evolve following a set of rules and increments the simulated time of a fixed quantity. As soon as the state change has been computed, the system starts the computation of a new step. A \textit{Time-stepped} execution could be convenient in a simulation to be executed in the shortest possible time.
\end{itemize}

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.75\textwidth]{simulation_paradigms}
    \caption{ Simulation systems classification \cite{0}  }
\end{figure}

One example of \textit{Time-stepped } execution is the \textbf{Cellular Automata} model. This simulation paradigm, often used to model natural processes,  provides for a data structure representing the physical space, composed of a huge amount of \textit{Cells} which evolve following the same fixed rules. Because in this kind of simulation, the main aim is to make the execution as fast as possible and because of how a \textit{Cellular Automaton} evolution works, the most intuitive way to increment the performance is to split the huge amount of elementary computations concerning all the \textit{Cells} into the space, between multiple CPUs, so that the execution is performed in parallel and in minor time. However the parallelization of the execution entails some overhead, coming from the resolution of the problems resulting from the distribution process, one of whom is the information exchange between the parallel CPUs, needed to make evolve the \textit{Cells} on the \textit{Borders} of their space portions. The just mentioned communication is often performed using the \textbf{MPI} technology, which is an \textit{API}, standard de facto for parallel applications which are designed to follow a message passing model. In the literature of the \textit{Parallel and distributed discrete-event} simulation systems, there are many general valid solutions that could be applied to the specific case of \textit{CA}. One of the most interesting concepts in this literature is the \textbf{LookAhead} applied to the \textbf{Synchronization Problem}. This problem occurs when two parallel processes, running portions of the same simulation, can invalidate their executions each other, affecting their respective simulated past, that's to say creating events with a timestamp minor then the actual value of simulated time. The \textit{LookAhead} is a concept whose understanding is necessary to solve the problem, because it is a value which ensures to each parallel process, a lower-bound, in terms of simulated time, to the timestamp of the next event that could affect its simulation. \\
As suggested from the title, this thesis' main aim is to examine in depth some aspects of \textit{Cellular Automata} that may result in overhead reduction and performances improvements, when this kind of simulation is executed in a Parallel and Distributed Environment. Most specifically our focus will be on the notion of \textbf{Idle Cell}, well known in CA's literature and the just mentioned \textit{LookAhead}. Using these two concepts, it has been tried to come out with an algorithm to reduce the parallelization overhead.
\newpage
\chapter{Cellular Automata}
%Chp 2.1
\section{\textit{CA}'s definition}
Introduced by mathematician John von Neumann in 1940s, a \textit{Cellular Automata(CA)} is a discrete computational paradigm, studied in computer science, mainly used to simulate complex phenomenon whom behavior derives from the basic local interactions of spacial units named \textit{Cells}. A \textit{CA}, as said before, is composed of a  data structure which represents the space where the simulated phenomenon takes place. This data structure, often a matrix, is composed of many elementary units named A \textit{Cells}, therefore this structure is called cellular space. The evolution of the entire simulation is strictly related to the evolution of  all its elementary spacial units. A \textit{Cell}'s evolution, for its part, is related to the application of certain rules at every step of the simulation. Even if the rules of a \textit{CA} can be applied to an infinitely extended space, in a real simulation most of the time the number of \textit{Cells} is finite. Every \textit{Cell} interacts with a relatively narrow number of other \textit{Cells} whom state affect its evolution. The set of \textit{Cells} which affect the evolution of every spacial unit depends on the \textit{Neighborhood} relation. This latter is bound both to the simulated model and the various types, known in literature, which the modeler can choose from. \\

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.5\textwidth]{neigh_types}
    \caption{  From the left to the right, Von Neumann and Moore Neighborhood  with radius equal to one \cite{1} }
\end{figure}

The \textit{Neighborhood} relation is a geometrical pattern, which relates a set of \textit{Cells}, fixed for every \textit{Cell} and every step of the simulation's evolution. The two most widely adopted kinds of pattern existing in literature, appreciated for their simplicity and however effectiveness, are the following:
\begin{itemize}
\item
\textit{Von Neumann Neighborhood} : Fixed a number said radius, each \textit{Cell} in any direction whom distance from the one considered, for instance called C1, is minor or equal to the radius, is said to be in the \textit{neighborhood}, according to this definition.
\item
 \textit{Moore Neighborhood} : Fixed the just mentioned radius, for instance R, is said to be in the \textit{neighborhood} every \textit{Cell} whom all coordinates are distant from C1 at most R.
\end{itemize}


As reported before, the evolution of every \textit{Cell} at a certain point of the simulation is uniquely given from the internal state and the state of the \textit{Neighborhood}. For each particular model there are a certain number of simple rules which have the aforementioned states as input and the next state of the \textit{Cell} as output. From this point of view, each \textit{Cell} evolves as a \textit{FSA (Finite State Automaton)}. Despite this simulation paradigm may seem trivial, it is still very relevant for getting to see the chaotic and complex evolution of the entire model at a macroscopic level.\\
Let's think about \textit{Conway's Game of Life}, a famous cellular automaton very studied in the 1970s. This is a two state and bi-dimensional automaton which elementary rules are the following :
\begin{itemize}
\item
A \textit{Cell} in the state \textbf{1} with a number of neighbors in the state \textbf{1} fewer than two goes to the state \textbf{0}
\item
A \textit{Cell} in the state \textbf{1} with a number of neighbors in the state \textbf{1} greater than three goes to the state \textbf{0} 
\item
A \textit{Cell} in the state \textbf{1} with a number of neighbors in the state \textbf{1} between two and three remains in the same state
\item
A \textit{Cell} in the state \textbf{0} with a number of neighbors in the state \textbf{1} equal to three goes to the state \textbf{1}
\end{itemize}
One of the most interesting aspects of this \textit{CA} is that from some randomized initial configurations of the \textit{Cells} in the simulated region, through its evolution this automaton shows a constant presence of some self-replicating structures, known as \textit{Gliders}, generating from some other structure type known as \textit{Gliders-Gun}. It can be proved that manipulating the initial configuration of the \textit{CA} to generate \textit{Gliders-Gun} and therefore \textit{Gliders}, in certain \textit{Cells} of the space, there will be certain interactions similar to computations. This aspect allows us to say that the aforementioned \textit{CA} can emulate a \textit{Turing machine}.\\
This example gives us an hint about \textit{CA} simulation paradigm's potentiality as well as it's capability of modeling complex systems behavior, starting from very elementary rules.
%Chp 2.2
\section{Parallel execution of \textit{CA}}
Since a \textit{CA}'s evolution consists of applying the same elementary rules (\textit{Transition Function}) to an huge number of \textit{Cells} in the simulation space, distributing the computation on many process in order to speed up the overall time of the simulation, may seem reasonable and straightforward to carry out. The most intuitive way to distribute \textit{CA}s is to split the cellular space in regular and contiguous portions and delegate the application of the \textit{Transition function} on each portion, to a process into the parallel environment. The subject's literature shows several ways of making such a split, depending on the topology of the \textit{CA}, its \textit{cells}'s shape and the dimensions of the cellular space. In fact the split can be made along one or more dimensions. The latter case can make the split more complex.

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.5\textwidth]{split_types}
    \caption{  Some split examples : Mono-dimensional and Two-dimensional for a \textit{CA} with two dimensions and squared \textit{Cells} \cite{1}}
\end{figure}

Let's now think about the evolution of the \textit{CA} after being split and distributed to various processes, and let's focus on what happens for a \textit{Cell} close to the cut of the split that as been made. The informations about the \textit{Neighborhood} of such \textit{Cells} are located partly in the process which makes it evolve, but the remaining part is missing. In fact some of the \textit{Cells}'s  informations are located into that processes which have been delegate of apply them the \textit{Transition Function}. This trait is effective for every \textit{Cell} along the aforementioned cut. It is therefore reasonable to address the entire set of \textit{Cells} with this property and whom \textit{Neighborhood}s reside into the same process with a proper name : \textit{Border}. The process containing the \textit{Border} and the one containing the \textit{Neighborhood} of it's \textit{Cells} are said to be adjacent processes. 

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.75\textwidth]{missing_neigh}
    \caption{  Missing \textit{Neighborhood} of a \textit{Cell} along the cut \cite{1}}
\end{figure}

Because of the lack of information, before every discrete step of the simulation an interchange of information is required between every couple of adjacent processes, each sending his \textit{Border} and receiving another one from the respective coupled process. 

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.5\textwidth]{border}
    \caption{  Example of a couple of processes and their related borders \cite{1}}
\end{figure}

This preparatory operation, before the application of the \textit{Transition Function}, introduces a performance's overhead strictly bonded to the parallel distribution of the computation. If such overhead could be avoid or just reduced, the performance gain resulting from the parallelization would be higher. The main aim of the study that is going to be shown in this thesis, is to find out some algorithm to exactly temper the mentioned overhead and obtain the related performance gain. 



%Chp 2.3
\section{Technologies and Frameworks }
As we have seen the interchange of \textit{Borders} between processes, is suitable for a communication paradigm that uses messages. To implement this communication, has been chosen to use the well known \textit{MPI(Message Passing Interface)} technology. It was designed as a language independent API (Application Programming Interface), in order to increase the portability of the applications using this technology, but however it has various implementations in many programming languages, among which the \textit{C++} version was used in the implementation of the conceived mechanism. \textit{MPI} is a standard for the communication of nodes in a cluster and is often used for high performance computing. The nodes in the cluster are often addressed as "processes" or "logical processes" and are grouped in so-called \textit{Communicators} within which they are arranged along various topologies. The processes in this topology mainly talk in point-to-point (\textit{p2p}) mode, and both blocking and non-blocking two-side communications are used. The main two couples of blocking and non-blocking methods are respectively \textbf{MPI\_Send - MPI\_Recv} and \textbf{MPI\_Isend - MPI\_Irecv}. When a non-blocking approach is chosen, at a stage of reception of the messages, a process has to be able to test or be notified when the operations are actually completed. One of the possible ways to perform such test of reception, is to use the method \textbf{MPI\_Iprobe}, which ,without blocking the execution flow, samples the message receiving. In order to perform a \textit{p2p} communication, each of the interlocutors has to know the ID of the other one within the \textit{communicator}. Moreover the data type of the informations to be transmitted have to be agreed. In addition to all the native types, corresponding to the native types of the majority of the programming languages, the standard MPI-1.2 provides for the definition of new data types (\textbf{MPI\_Datatype}). 
\\Thanks to this and other technologies, over time have been developed many frameworks for the parallel execution of \textit{CA}. Some examples of frameworks, developed at the \textit{"University of Calabria"}, are the following :
\begin{itemize}
\item
\textit{OpenCAL} : Modeling system for \textit{CA}
\item
\textit{libAuToti}: Library for \textit{CA} implementation using MPI
\item
\textit{CAMELot}: Parallel development environment for \textit{CA}
\item
\textit{VinoAC}: Framework for transparent execution of \textit{CA} in parallel and distributed environment, using \textit{MPI}
\end{itemize}
Among these frameworks, \textit{VinoAC} is the one that has been expanded with a module that, as said before, tries to temper the overhead caused by the interchange of \textit{Borders} and obtain a gain in performance terms.

\section{\textit{Cellular Automata}  applications}

Like it has been pointed out before, even in the \textit{CA} case there are many useful applications, some of whom are particularly fitting for this model, despite another simulation paradigm could also be used. The introduction of this report illustrates several examples of fields where the usage of a simulation system could be advantageous. However, again, not each of that examples are befitting for the  \textit{CA} paradigm, so here are the most appropriate ones:
\begin{itemize}
\item
\textit{Cryptography} : Since, to days, a great percentage of the activities in the world of work makes use of the internet to exchange sensitive and personal informations, the \textit{cryptography} field is gaining more and more relevance in order to come out with mechanisms that preserve the confidentiality of these informations. In this context, it could turn to be useful the usage of \textit{CA} to create a \textit{cryptography} key. It's in fact very important in this field to create a strong key, thanks to which the informations can be encrypted, whom prediction is statistically unworkable. \\
As said before the evolution of an entire \textit{CA} is often really complex as a whole,  in spite of the elementary rules from which descends. Therefore, one could apply to a random initial configuration of a \textit{CA} a \textit{Transition Function} for a random number of times, in order to obtain an unpredictable state to fully or in part use as a key. The reliability of this method is discussed thus far, but it can be proved that the time complexity required to perform an attack to such a key is exponential.
\item
\textit{Artificial Life} : Is known for some time now, in the field of Biology, that many composite organisms, which seem to have a sentient behavior at a certain degree, is actually driven by the basic interactions of elementary insentient components. This components are often static in the space and therefore can only interact with the other components which are near to them. In view of this, many biologists come out with the idea of applying the \textit{CA} simulation paradigm to this complex systems, since it is clear how the model is very fitting to this context, in order to simulate the just mentioned interactions and study more efficiently these phenomena. A well known example is the aforementioned \textit{Conway's Game of Life}, which is a simple but very didactic model to understand the potential of such simulations for fields like the \textit{Populations Ecology and Biology}. 

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.75\textwidth]{artificial_life_ca}
    \caption{  Bacterial Hyperstructures simulated with a \textit{Cellular Automaton} \cite{2}}
\end{figure}

One last example which could sound more relevant and even of tendency for the field of computer science nowadays, is the case of the \textit{Cellular Neural Networks (CNN)}. Even in this case in fact, as known, a \textit{Neural network} is a computational model inspired by the functioning of the human brain,  that's to say how its complex behavior depends on the interactions between the neurons. The applications of a \textit{Neural Network} are well known in literature and won't be debated here, however it's important to underline that a \textit{CNN} model differs from a classic \textit{Neural Network} because in the first case the information exchange is allowed only between neighboring units, like in a \textit{CA}.
\item
\textit{Scientific Modeling} : The final, but most relevant, application discussed here is for the field of the \textit{Computational science}. The main aim in this sphere is to come out with computable models, that can solve mathematical or physical problems, or simulate a natural process and therefore be able to predict its effects and avoid the potential damages. Among the several possibilities discussed already, a \textit{CA} is the one more appropriate for those phenomena which, as said before, are regulated by simple local rules. 

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.75\textwidth]{LGA}
    \caption{  Lattice Gas \textit{cellular Automaton (LGA)} \cite{2}}
\end{figure}

Such paradigm is in fact often applied to model natural processes comparable to the flux of fluids. A famous example is the one of the \textit{Lattice Gas cellular Automaton (LGA)}, well studied in the 1990s, which models, in various versions, exactly fluid flows and has led to several mathematical results, even in a continuous form. Another \textit{CA} model, that will be discussed in the next chapters as a study case for this research work, is the so-called \textit{SciddicaT}. This model simulates, even here, a flow of rubbles rolling down along a ridge which then may active a landslide.
\end{itemize}

This discussion has only mentioned a small number of fields of application for a \textit{CA} and only the most relevant ones, for our purposes, have been chosen. Between these, the field of the \textit{Computational Science} was the one inspiring this thesis and the starting point for the results that came out from the research work, even if these latter can be applied in other spheres.

\newpage
\chapter{\textit{D}istributed discrete-\textit{E}vent \textit{S}imulation }{\Large{\textit{DES}}}\\
%Chp 3.1
\section{Parallel Environments and Execution paradigms}
Even if the main aim of this research work was to think up to an algorithm, ensuring the consistency of the simulation's results and a good speed-up,  without hardware or software constraints, so that it can be as much generally strong as possible, sometimes certain assumption on the parallel environment's characteristics have turned necessary. It can be useful for this reason to get a quick overview of the primary traits which distinguish a parallel environment, in order to later understand the development choice that have been made. \\
First of all let us talk about the several possible hardware platforms. The main categorization differentiates the following machines, in the way all the informations are stored :
\begin{itemize}
\item
Shared memory Multiprocessors : Multiple processors share the same physical memory, hence every change to the data is visible to the other processors immediately
\item 
Distributed memory Computers : Multiple computers often heterogeneous have their own memory. If one of the computer modifies some data in its own local memory, and some other one needs exactly that data, some kind of message exchange is need. For this kind of architecture is very common the employment of general purpose connection networks rather than some customized one. This results in much more latency for the communication
\end{itemize}
More targeted architectures exist and have better performance than those aforementioned, however it doesn't make any sense to talk about an algorithm for such architectures here.
\newpage
\begin{figure}[ht!]
\centering
    \includegraphics[width=0.95\textwidth]{parallel_architectures}
    \caption{  From the left to the right, shared memory multiprocessors architecture and distributed memory computers architecture \cite{0}}
\end{figure}
%FIGURA 
In second place, we can categorize the various paradigms for the parallel execution of a program, which can be summarized in these types :
\begin{itemize}
\item
\textit{SPMD(Single Program Multiple Data)} : The same executable is launched multiple times and different data in input (often one of these is some process ID)
\item
\textit{MPSD(Multiple Program Single Data)} : For every kind of task, a targeted program is created
\item
\textit{MPMD(Multiple Program Multiple Data)} : Less used paradigm, arrangement of the first two in this list
\end{itemize}
The parallel environment whom this text will refer from now on, belongs to the category of the Distributed memory architectures and uses the SPMD paradigm execution, even more because the latter is used in many \textit{C++} implementation of the \textit{MPI} technology, considered in the previous chapter. \\
	Besides the one made before, a further observation about the communication network concerns the reliability and the keeping of the sending order. In the conception of the algorithm, purpose of this work, it has been assumed a 100\% reliability of the connection network between the processes in the parallel environment, as well as it has been assumed that, traversing the network, the sending order of the messages doesn't change. This trait will result clearly important in the next chapter.
%Chp 3.2
\section{Discrete Event Simulation}
The \textit{Discrete-Event Simulation} paradigm's attempt, is to model the evolution of some real system with a chain of consecutive states, which stay unvaried for a definite amount of time preceding an instant when the system is thought to evolve immediately and enter in a new unchanging state. In this context the temporal dimension is very important to uniquely identify the state of the simulation, but it turns out to be necessary to give a definition of all the different "kinds" of time that can be encountered in the treatise. In the literature \cite{0} there are the following definition, which are really relevant for the considerations that are going to be \\
made :
\newpage

\begin{itemize}
\item
\textit{Physical Time} : Is the amount of time that would have elapsed, between two events or instants during to phenomenon being simulated, into the real world
\item
\textit{Simulated Time} : Is an abstraction of the \textit{Physical Time}, used inside the computer context to remark the state of the simulation's evolution
\item
\textit{Wallclock Time} : Is the amount of time taken from a machine to perform all of the necessary computations to make the simulation evolve to a certain \textit{Simulated Time}. Obviously the latter quantity depends on the hardware executing the aforementioned computations
\end{itemize}
Related to the disambiguation of the overlying terms, it may be useful to briefly examine how the \textit{Simulated Time} can be handled, in terms of how fast but also what is the reason of its increment. The main partition, concerning the haste of the simulation's execution, is into : 
\begin{itemize}
\item
\textit{Real time Simulation} : This kind of simulation needs the human interaction, maybe waiting for some input or simply a check. A military simulation, targeted for an airplane's pilot, may be an example of application where this approach is necessary, even if it slows down the execution time
\item
\textit{As fast as possible Simulation} : When the simulation doesn't need any kind of external input, but the main purpose is to speed-up the execution, in those cases this approach is the most appropriate 
\end{itemize}
Totally clear from the above partition, is the one concerning the reasons of every discrete state's change. In fact depending on the model being simulated, a simulation is said to be :
\begin{itemize}
\item
\textit{Event driven} if the events internal or external to the simulation, cause a change to the state and the \textit{Simulated Time}
\item
\textit{Time stepped}, more suitable for an execution \textit{As fast as possible}, if the simulation doesn't need any input to evolve and therefore when a state is completely set, the next one can be computed
\end{itemize}
A \textit{Time stepped} approach seems befitting for a \textit{CA} model, because its evolution consists of reading the state a the step \textit{t} of the \textit{Simulated Time} and then compute the state of the \textit{CA} at the time \textit{t+1}, without any other requirement.
%Chp 3.3
\section{The synchronization problem and lookahead}
As previously occurred in this treatise, when a sequential algorithm is transposed into a parallel environment, then some problem to be solved comes out. That's exactly the case for a \textit{Discrete Event Simulation}'s parallelization. \\
For instance in a Distributed environment containing heterogeneous machines, it is not that difficult to find out that at a given instant in the \textit{Wallclock Time} two different processes have reached different points into the \textit{Simulated Time}. Let's call this two processes \textbf{Lp1}(standing for \textit{Logical process}) and \textbf{Lp2}, and let's say Lp1 has reached a point into the \textit{Simulated Time} successive to the point reached from Lp2. If Lp1 and Lp2 can respective computations, the discrepancy between the \textit{Simulated Time} instants could be a problem, when Lp2 affects Lp1 in its past. Lp1 in fact would need to handle that event which potentially could have changed its state if it had arrived earlier in the \textit{Wallclock time}. In this case Lp1 is said to violate the \textit{Local Causality Constraint}, defined in literature as follows :
\begin{quotation}
\textit{Local Causality Constraint} : A discrete-event simulation, consisting of logical processes (LPs) that interact exclusively by exchanging time stamped messages obeys the local causality constraint if and only if each LP processes events in non-decreasing timestamp order \cite{0} 
\end{quotation}

To obviate to this issue one has to come up with some algorithm to prevent a situation like the one mentioned. The algorithms solving this problem can be categorized in two groups : 
\begin{itemize}
\item
\textit{Conservative approach} : An Lp can wind on only if it has the assurance to not receiving any message or event that could affect its past states
\item
\textit{Non conservative approach} :  An Lp planning to not receive anything affecting its past can wind on, but has to perform a roll-back operation if receives such a message or event
\end{itemize}
When a \textit{Conservative approach} is chosen an Lp at an instant \textit{t} can process an event with a timestamp \textit{t+l1} or make the simulation advance to the step \textit{t+l2}, only if it is sure that nothing with a timestamp less then \textit{t+l1} or \textit{t+l2} will be received. To make such assumption an Lp must have enough information about which other Lps in the simulation can affect its execution an particularly the value of the so-called \textit{Lookahead}. The latter is defined as follows :
\begin{quotation}
\textit{Lookahead} : If a logical process at simulation time \textit{\textbf{T}} can only schedule new events with time stamp of \textit{at least} \textit{\textbf{T+L}}, then \textit{\textbf{L}} is referred to as the lookahead for the logical process \cite{0}
\end{quotation}
To underline the relevance of this quantity, let us thing for instance to a situation when it equals zero. Under this condition an Lp cannot process any event or wind on to the next step because then it could receive a message violating the \textit{Local Causality Constraint}. In the next chapter the importance of this concept is going to result even more strong, when a parallelism with \textit{CA} paradigm will be drawn. 
\newpage
\chapter{Application of \textit{DES} techniques in Parallel execution of Cellular Automata}
\section{Synchronization problem for \textit{CA}}
As a first step of this research process, it has been tried to study the synchronization problem applied to the \textit{CA} paradigm in a parallel and distributed environment, in order to came out with some kind of \textit{Conservative} algorithm which could prevent the infringement of the \textit{Local Causality Constraint}, in a situation where every Lp handles a different automaton with its own time step, in terms of \textit{Simulated Time}. In that situation the different \textit{CA} would have been modeling different phenomena into the same complex system, and therefore would have been related to each other.\singlespacing Since also in this case an algorithm with the most general validity was wanted, the problem has been modeled around two main data structures. The first one is a dependency graph, dynamically configurable, which denotes for each Lp in the simulation, those which it can affect and those which can affect its own simulation. Let's call it \textbf{dependency\_graph}. Let this structure be composed by two lists, one containing the IDs of the Lps on which one depends, and the other containing the IDs of the Lps depending from it. Let's call the lists respectively \textbf{incoming\_arcs} and \textbf{outgoing\_arcs}. The second data structure is a vector containing the time step information. In particular, each Lp has two vectors, one containing the information about the Lps which depend from it, and a second one containing the information about the Lps on which it depends. It is important to say that just because of its connotation of general validity, any focus was given on the kind of information that a generic couple of processes has to exchange each other. The only constraint which is supposed to bound the evolution of every Lp, is that it has to receive from every Lp on which depends, its latest state informations as well as it has to send its own state information to let wind on the Lps which depend by it. Let's call the two vectors respectively \textbf{outgoing\_steps} and \textbf{incoming\_steps}.\\
After the element appearing in the algorithm being discussed, it's time to discuss its functioning as well. It will be used an example here, in order make the presentation of the algorithm easier. For instance immagine two processes Lp1 and Lp2 designated to make evolve in parallel environment, a couple of interdependent \text{CA}. Lp1 has a time step of 2 units meanwhile Lp2 has a time step of 9 units and depends on the first one. After a preparatory informations exchange at the \textit{Simulated Time} 0, every process is ready to evolve at the next step, therefore Lp1's \textit{Simulated Time} goes to 2 while instead Lp2 goes to 9. Because of its dependency from Lp1, Lp2 now can't evolve to the next step until Lp1 reaches the greatest instant until it moves into the future of Lp2. Lp1 instead can safely advance to time step 8 with 3 transitions. After performing every transition both Lp1 and Lp2 update not only their own time reference but also a reference for every of their related Lps. In our case Lp1 updates a reference to the time of Lp2 and Lp2 updates a reference for Lp1's time. It is exactly for this reason that when Lp1 hits the time step at the \textit{Simulated Time} 8, knowing the time step of Lp2 read from the vector \textbf{outgoing\_steps} can say it needs to send its state's informations to Lp2 which is dependent from him. Symmetrically, for the same reason Lp2 can say that he needs to receive some information from Lp1 to be able to evolve. Subsequently to this informations exchange both Lp1 and Lp2 are able to procede with their own operations.
\begin{algorithm}
\label{alg:one}
\begin{algorithmic}
	\STATE /* \textit{Vector containing the step reached from }
	\STATE\ *\ \ \ \textit{every dependent Lp}
	\STATE\ */
	\STATE Simulated\_time\_outgoing{[N]}
	\STATE /* \textit{Vector containing the step reached from}
	\STATE\ *\ \ \textit{every Lp on which this one depends}
	\STATE\ */
	\STATE Simulated\_time\_incoming{[N]}
	
	\WHILE{\NOT SIMULATION\_END}
		\STATE Can\_do\_step = \TRUE
   		
		 \FORALL{ Lp \textbf{in} incoming\_processes}
			\IF {Simulated\_time\_incoming + incoming\_steps \textless MY\_CURRENT\_TIME}
				\STATE Can\_do\_step = \FALSE
			\ENDIF
		\ENDFOR
		
		\IF{Can\_do\_step}
			\STATE CA\_Transition()
			\STATE MY\_CURRENT\_TIME += step
			
			\FORALL{Lp \textbf{in} outgoing\_processes}
				\STATE MPI\_Isend(MY\_CURRENT\_TIME)
			\ENDFOR
		\ENDIF
		
		\FORALL{Lp \textbf{in} incoming\_processes}
			\STATE incoming\_message = MPI\_IProbe(Lp)
			\IF{incoming\_message}
				\STATE MPI\_Recv(Lp)
				\STATE Simulated\_time\_incoming += incoming\_steps
			\ENDIF
		\ENDFOR
		 
 	 \ENDWHILE
 	 
\end{algorithmic}
\caption{run\_simulation() \textit{Pseudo-code of the algorithm's main loop}}
\end{algorithm}

Like one can see from Algorithm \ref{alg:one}, in a real situation with a more complex dependency graph, thanks to the \textit{MPI}'s non-blocking functions \textbf{MPI\_Isend} and \textbf{MPI\_IProbe} any deadlock situation can be prevent. Furthermore, again thanks to \textit{MPI}, the algorithm doesn't need to implement any acknowledgment mechanism to make sure that every dependent Lp knows about the advancement of the simulation in another process because, as said before, the \textit{MPI} communication network can thought with a perfect reliability. \\
Even if this algorithm can be useful in certain situations, the effort to think up such a mechanism was minimal as well as it's minimal its scientific significance. In fact it doesn't profit by any of the aforementioned \textit{DES} techniques nor brings to any performance gain in the execution of such kind of simulation. The reason is that every \textit{CA} simulation can be categorized as a time-stepped simulation and moreover in usually it's evolution depends on its own internal state. A general mechanism as the one just described is meaningless if any assumption, about how the execution of a \textit{Cellular Automaton} can be affected, can be done. 
\section{\textit{Lookahead}'s study for border swap avoidance}

Things are different if we talk about the execution of a single \textit{Cellular Automaton} distributed through a parallel and distributed architecture. In this case in fact, every Lp which is assigned to make evolve a portion of the cellular space is inherently bound to the other Lps in the simulation. In this context, as seen in the section dedicated to the Parallel execution of \textit{CA}, every couple of adjacent Lps, has to permanently communicate, asking and being asked about their respective \textit{Borders}. Because of this, in the second phase of the study work, the main focus has been on finding a way to moderate the overhead due to that communication.\\ 
In particular an Lp containing a \textit{Border} that has not changed, in any of its cells, after applying the \textit{Transition Function}, in principle doesn't need to transmit that \textit{Border} again. Unfortunately there is an issue here regarding the possibility of run into a \textit{deadlock} situation. So, if for example an Lp skips a transmission, its adjacent interlocutor, which expects this information after every step of the evolution, will freeze its execution. Thus, a mechanism to let every the Lps know when to receive or send a \textit{Border} is needed. In other words each Lp needs a \textit{Lookahead} information about every of its adjacent interlocutors. However, to find a value for such information one needs to find some middle ground between a general valid concept and something dependent on the model. The middle ground was found into the \textit{CA}'s concept of \textit{Idle Cell}. A cell whom state doesn't change after applying the \textit{Transition Function} is said to be and \textit{Idle Cell}. This concept is particularly relevant if one thinks of the possible assumptions that can be done about the evolution of a \textit{Cell} with another \textit{Idle} one in its \textit{Neighborhood}. For instance it's not unreasonable to think that under certain conditions such \textit{Cell} could take two steps to change its state. Applying the same reasoning recursively to \textit{Cells} more and more distant from an active one, likewise the number of steps to change their state could grow up. In this way an Lp can find a value of \textit{lookahead} for its borders if considering the \textit{Idle Cells} in its own Cellular space and in its adjacent Lp's ones. It seems clear, from the previous arguments, that a \textit{lookahead} calculated with this assumptions, has to be directly proportional to the distance from the nearest active \textit{Cell} of each border.
\section{The starting point for the implementation}
Since, unlike in the first algorithm's event, in this case there are many frameworks already implemented which are delegated to run a \textit{CA} in a parallel and distributed environment, it was decided to use one of these as a starting point. Between several of these, it was decided to use the \textit"University of Calabria" 's framework named \textit{VinoAC}. In particular, this framework has been extended with a module whom functioning will be shortly explained. As said in the past chapters, \textit{VinoAC} is a framework for the transparent execution of a \textit{CA}. The modeler has only to specify its model's elementary rules and then to start the simulation, without caring about the internal mechanism which permit the execution. This framework was developed in \textit{C++}, thus it has an Object-oriented structure. Its architecture was designed to permit the usage of different parallel communication paradigms, but the only implementation to date uses the aforementioned \textit{MPI} paradigm. The three primary classes in the framework architecture\\
are the following :
\begin{itemize}
\item
\textit{\textbf{Model2D}} : This is an object containing all of the model's information. The framework provides a basic interface to be extended for every specific CA. After one overrides the class's method which represents the transition function the simulator can make the CA evolve.
\begin{lstlisting}[language=C++,
                   directivestyle={\color{black}},
                   emph={int,char,double,float,unsigned},
                   emphstyle={\color{blue}},
                   caption={Model2D.h, Interface to be implemented by the Modeler},
                   captionpos=b
                  ]
#ifndef MODEL2D_H
#define MODEL2D_H

#include <Space2D.h>

template <class T>
class Model2D
{
  protected:
    Space2D<T> *space;
  public:
    void setSpace(Space2D<T> *space);
    virtual void init() = 0;
    // Transition function of the (x,y) cell
    virtual void transitionFunction(int x, int y) = 0;
    virtual void finalize() = 0;
    virtual ~Model2D();
};
#endif
\end{lstlisting}
\item
\textit{\textbf{Space2D}} : This is an object whose job is to handle the cellular space. The modeler doesn't need to know if the cellular space is distributed in multiple processes or is computed in sequential. As we said before, the basic interface is designed to be implemented using different communication paradigms, but the one used from the conceived algorithm uses the \textit{MPI} paradigm. This object contains two matrix representing the cellular space. From the matrix \textbf{regionCurr} the simulator reads the current state of the \textit{CA} and applying the \textit{Transition Function} it writes the new state into the matrix \textbf{regionNext} and then calling the method \textbf{swap()}, the latter matrix is copied into the first one.
\newpage
\begin{lstlisting}[language=C++,
                   directivestyle={\color{black}},
                   emph={int,char,double,float,unsigned},
                   emphstyle={\color{blue}},
                   caption={Space2DMpi.h, Space handler using the MPI paradigm},
                   captionpos=b
                  ]
//Class for a two-dimensional CA space when the MPI technology is adopted
#ifndef SPACE2DMPI_H
#define SPACE2DMPI_H

#include <Space2D.h>
#include <Element.h>

template <class T>
class Space2DMpi : public Space2D<T>
{
protected:
  enum Direction  { N, NE, E, SE, S, SW, W, NW};

  int currentStep = 0;
  // Read matrix
  T *regionCurr; 
  // Write matrix
  T *regionNext; 
  
  void updateBorders();
public:

  void swap();
};

#endif
\end{lstlisting}

\item
\textit{\textbf{Engine2D}} : This is an object whose job is to pull together the two previous objects. It reads the informations from the model and then it changes the state of the \textit{CA}. After initializing the simulation, the method \textbf{start()} is called. This method contains the main loop of the simulation. 
\begin{lstlisting}[language=C++,
                   directivestyle={\color{black}},
                   emph={int,char,double,float,unsigned},
                   emphstyle={\color{blue}},
                   caption={Engine2D.h, The engine running the simulation and the main loop method},
                   captionpos=b
                  ]
#ifndef ENGINE_H
#define ENGINE_H

#include <Model2D.h>
#include <Space2D.h>


//Base class for the engine running a 2D cellular automata

template <class T>
class Engine2D{
    protected:
    // The CA space
    Space2D<T>* space;
    // The application model
    Model2D<T>* model;
    // The number of steps
    int nsteps;
    
public:

    void setSpace(Space2D<T> *space);
    void setModel(Model2D<T> *model);
    //Sets the number of steps
    void setNsteps(int nsteps);    
    void start(){
    	// Initialize the cellular space
    	model->init(); 
    
    	for (int step = 0; step < nsteps; ++step){
			space->setCurrentStep(step);
			// Initialize the step
			space->startStep(step); 
			for (int x = minX; x <= maxX; ++x)
				for (int y = minY; y <= maxY; ++y)
					// Apply the transition function to every cell in the space
					model->transitionFunction(x,y);
			// Write regionNext into regionCurr matrix
			space->swap();
		}
    }
};

#endif
\end{lstlisting}
\end{itemize}
This framework has been chosen as a starting point of the implementation phase of this work, due to its suitable architecture presenting a clear division between the \textit{CA}'s model and its cellular space. But, even if \textit{VinoAC} was a good starting point, some criticality were found into the \textbf{Space2D} class and in the way it handles the \textit{Borders} exchange.
\section{\textit{VinoAC}'s \textit{LookAhead} module}
Since \textit{VinoAC} implements the classic execution of \textit{CA}, the class \textbf{Space2D}, after each step of the simulation, takes care of the \textit{Borders} exchange between every couple of adjacent Lps. That's exactly why the first thing clearly to modify was this class and more specifically its method \textbf{startStep(int step)} which contains all the preliminary operations to each step of the simulation's evolution, including the \textit{Borders} communication. Secondly a way to know if a \textit{Cell} is \textit{Idle} seems necessary, therefore the base class \textit{Model2D} has been extended with the addition of a the method \textbf{bool isStanding(int x, int y)} by which it is possible to ask for such information to the specific \textit{CA} model. With these elements being given, the only remaining thing to do is to explain the main algorithm's functioning. \\
The algorithm consists of two parts, one which dynamically updates the lookahead value for each adjacent Lp of the one considered, during the application of the \textit{Transition Function}, and the other which handles the conditional exchange of the \textit{Borders} or some other related information. The second part is the one that's going to be explained first. \\
Consider as usual, two adjacent processes Lp1 and Lp2. Let's consider only the Lp1's point of view as a simplification in order to better understand the functioning of the mechanism. With this assumption we mean to say that Lp1 is the sender of the \textit{Border} whereas Lp2 is intended to only play as the receiver. Suppose also that in an initial phase both Lp1 and Lp2 know about the \textit{LookAhead} value related to the communication that they usually do at every step. From now on we'll refer to this value with the symbol \textit{LAh}. Considering what the \textit{LAh} value means, that's to say a promise that the \textit{Border}, known from both the Lps in an initial phase, won't change for the next \textit{LAh} steps, then an Lp can make evolve its portion of cellular space for that number of steps, saving itself the overhead caused by the usual communication operation. Obviously every both Lp1 and Lp2 are meant to decrement their local reference of the \textit{LAh} value after each step of the evolution, in order to contemporary reach a situation where the reference equals 0, meaning that the \textit{Border} well know until that moment could have changed and therefore the Lps need to perform some kind of communication to figure out what to do next. 
After reaching this point, Lp1 computes a new value of \textit{LAh}, which as known is a non-negative integer. Accordingly to the resulting value, a choice takes place : 
\begin{enumerate}
\item
If the \textit{LAh}'s value is strictly greater than zero, that means the \textit{Border} won't in effect change. It's important in fact to underline that the \textit{LookAhead} value in a context of general validity, is intended to represent only a lower bound for the real number of steps that a \textit{Border} needs to change. The modeler in effect could be unable to make such strong assumptions on the simulated phenomena to come out with an exact value of \textit{LAh}. Since it has this information, Lp1 notifies Lp2 that the \textit{Border} won't change sending a message with tag \textbf{LookAhead\_Update}, containing the new value. Lp2 after decrementing to zero its reference to \textit{LAh}, puts itself in listening of some message. Reading the tag of the message sent from Lp1 updates its reference of \textit{LookAhead} and resumes its execution.

\item
If otherwise the \textit{LAh}'s value equals zero, that means the \textit{Border} will change after the \textit{Transition Function} is applied. Therefore Lp1 sends a message with tag \textbf{LookAhead\_Update\_Following\_Border}, meaning that it will send the new \textit{Border} into the next step. Then, just after the \textit{Transition Function} is applied and the \textit{Border} has changed, Lp1 sends a message with tag \textbf{Border\_Update}, containing the new boundary informations. Lp2 which was waiting for a message, receives the one with tag \textbf{LookAhead\_Update\_Following\_Border}, applies the \textit{Transition Function} and then receives the new \textit{Border}.
\end{enumerate}
Thanks to this first part of the algorithm, an Lp which can compute the value of \textit{LookAhead} for each of its \textit{Borders} can improve its performance in the execution of the \textit{CA} moderating the overhead coming from the parallelization. It is clear that in a real situation each Lp has to communicate with several adjacent processes and it also has to play both the roles of \textit{Borders} sender and receiver. In order to avoid any \textit{deadlock} situation, even in this case the \textit{MPI}'s non-blocking functions fit our case. In fact, performing all of the send operations in non-blocking mode and then, playing the role of receiver, performing all of the receive operations, every Lp can avoid any kind of \textit{deadlock}.
\newpage
\begin{lstlisting}[language=C++,
                   directivestyle={\color{black}},
                   emph={int,char,double,float,unsigned},
                   emphstyle={\color{blue}},
                   caption={Space2DMpiLAh.h::\textbf{startStep(int step)}, implementation of the first part of the algorithm},
                   captionpos=b
                  ]
#ifndef SPACE2DMPILAH_H_
#define SPACE2DMPILAH_H_

template <class T>
class Space2DMpiLAh: public Space2DMpi<T> {
public:
void Space2DMpiLAh<T>::startStep(int step){
	//Two FOR cycles to avoid deadlock. The first one contains only non-blocking send
	for(int i=0;i<Neighbors_Number;i++){
		if(last_LAh_sent == 0){
			//To advance this Lp's neighbor needs some info about this Lp's border
			int new_lookahead = computeBorderLookAhead(i);
			if(new_lookahead>0){
				/* When the new_lookahead value is still greater then zero,
				 * it means the border sent in the past still won't change for
				 * at least LAh number of steps
				 */
				MPI_Isend(LOOKAHEAD_UPDATE);
			}
			else{
				MPI_Isend(LOOKAHEAD_UPDATE_FOLLOWING_BORDER);
			}
		}else last_LAh_sent--;
	}
	// Receiver loop
	for(int i=0;i<Neighbors_Number;i++){
		if(last_LAh_received == 0){
			//To advance this Lp needs infos about neighbor's border -> SEND
			
			while(true){
				MPI_Iprobe(LOOKAHEAD_UPDATE);
				MPI_Iprobe(LOOKAHEAD_UPDATE_FOLLOWING_BORDER);
				if(RECEIVED_LOOKAHEAD){
					MPI_recv(LOOKAHEAD_UPDATE);
					break;
				}
				if(RECEIVED_LOOKAHEAD_N_BORDER){
					MPI_recv(LOOKAHEAD_UPDATE_FOLLOWING_BORDER);
					
					MPI_recv(border);
					break;
				}
			}
		}else last_LAh_received--;
		}
	}
}

};

#include "Space2DMpiLAh.ipp"
#endif /* SPACE2DMPILAH_H_ */

\end{lstlisting}
\newpage
The assumption of the discussed mechanism however, remains the computation of the \textit{LAh} value. As said before the \textit{LookAhead} is a quantity supposed to be, in the \textit{CA}'s case, proportional to the distance between those \textit{Cells} which are not \textit{Idle}, and the \textit{Border} of the cellular space's portion assigned to an Lp. \\
After underlining that even the proportionality above is an implementation choice, that could be invalidated in certain cases, we can say that for simplicity and for the purpose of letting the algorithm apply in general, it has been chosen to make the \textit{LookAhead} exactly coincide with that distance value. This chose allows to maintain the lower-bound connotation of the \textit{LAh}, compared to its computation as a quantity proportional to the distance, meaning it would have been a greater value. Because of the data structure used to represent the cellular space, that's to say a two-dimensional matrix, the computation of a distance occurs with constant time complexity (\textbf{\textit{O(1)}}), thanks to the indexing of every element in such data structure. Since the \textit{LookAhead} is a lower-bound to the number of steps needed from a \textit{Cell} on the \textit{Border} to become active and therefore change, requiring another \textit{Borders} exchange, then its value has to be computed as the distance between the nearest not \textit{Idle Cell} and each border. The crucial point is then to detect the nearest active \textit{Cell}. In order to do find this \textit{Cell}, each Lp has to iterate all over its portion of cellular space. Such iteration is also performed during the application of the \textit{Transition Function}, therefore one can take advantage of that and during this iteration check whether a \textit{Cell} is \textit{Idle } or not, and in the latter case compute its distance from each \textit{Border}, maintaining this value as  its \textit{LookAhead}, if it's smaller than the minimum at that moment. \\
In the \textit{VinoAC} framework, the iteration is delegated to the class \textbf{Space2D}, which has been extended in the \textit{LookAhead} module by the class \textbf{Space2DMpiLAh}. This class referring to the method \textbf{isStanding(int x, int y)} of the class \textbf{Model2DLAh}, can know if a \textit{Cell} is \textit{Idle}. Starting from this information, an Lp can save into a vector a \textit{LookAhead} value for each of its neighbors.
\begin{lstlisting}[language=C++,
                   directivestyle={\color{black}},
                   emph={int,char,double,float,unsigned},
                   emphstyle={\color{blue}},
                   caption={An implementation of Model2DLAh. The update of the lookahead's vector exploiting the iteration necessary to apply the \textit{Transition Function}},
                   captionpos=b,
                   label=lst:lahCompute]
#ifndef SCIDDICAT_H
#define SCIDDICAT_H
class SciddicaT : public Model2DLAh<T>{
	void transitionFunction(int x, int y){
		/*[...]*/
		/* Typical usage of the methods 
		 * isStanding and updateBordersLookaheadConsidering */
		if(!isStanding(x, y)){
			Space2DMpiLAh<T> *space_lah = dynamic_cast<Space2DMpiLAh<T> *>(space);
			space_lah->updateBordersLookaheadCosidering(x, y);
		}
				
	}
	bool isStanding(int x,int y);

};

#endif /*SCIDDICAT_H*/
\end{lstlisting}

As one can see from the Listing \ref{lst:lahCompute}, the class \textbf{Model2DLAh} thanks to its reference to \textbf{Space2D}, calls the method \textbf{updateBordersLookaheadCosidering}, to let the cellular space's handler update the vector containing all the \textit{LookAheads}. This last method  implementation simply computes the distance between the input \textit{Cell} and each \textit{Border} to later, with a conditional statement, update the just cited vector. If the cellular space would have been split with a two-dimensional cut, the resulting \textit{Borders} would have a complex shape, which would make the computation of their distance from a \textit{Cell} more difficult. Thus, in order to make these computations easier, it has been decided to apply to the cellular space a mono-dimensional cut. Thanks to this choice the \textit{Borders} between each couple of adjacent space portions, result to have a regular shape and therefore the computations of the distances happen in constant time. \\
As a final analysis, a relevant aspect to examine is the behavior of the discussed mechanisms, in the context of a real implementation. As seen before, the real computation has required several simplifications and adjustments of the mechanism even if it seemed to fit into an ideal setting. For instance, let's consider two processes Lp1 and Lp2 which both found in their portion of cellular space, that we suppose to be adjacent, two \textit{Cells} \textbf{C1} and \textbf{C2} respectively the nearest to the cut distinguishing the regions. Consistently with the distances of \textbf{C1} and \textbf{C2} from the \textit{Border}, both Lp1 and Lp2 compute the value of \textit{LAh} and in the majority of the cases the two values are different, because each Lp iterates only over its portion of cellular space, even if there could be a closer \textit{Cell} to the \textit{Border} but located in the adjacent portion of space. This inconsistency, could invalidate the entire simulation. The solution to this problem is merely to compute a minimum of the to values, respectively bound to the positions of \textbf{C1} and \textbf{C2}, on the occasion of the communication between Lp1 and Lp2, and consider the resulting value as the correct one. \\
Once this adjustments are done, the algorithm is ready to be effectively implemented without affecting the consistency of the simulation in any way. The last thing to examine thus is the performance improvement in terms of time, which, it must be remembered, is the main aim that prompted the ideation of the discussed mechanism.
\newpage
\chapter{Experimental Results and Performance Evaluation}{\Large{\textit{Test case : SciddicaT}}}\\
\section{Testing environment}
The final phase of this work has been the one during which a test suite to evaluate the performance of the algorithm has been run. In order to appreciate the efficacy of the parallelization process and the resulting speed-up growth with the growing of the number of Lps made available for the simulation, it has been necessary to use a powerful hardware configuration which could secure such processing capacity. Similar hardware was made available by the "University of Calabria" institute. Inside one of its buildings in fact, is located a \textit{cluster} named \textbf{JPDM1}, composed of several \textbf{Intel(R) Xeon(R) CPU E5-2670 2.60GHz } (8 Core- 16 threads) CPUs, with available 128GB of RAM memory each. Moreover, the various nodes are connected by a \textbf{Intel(R) Corporation I350 Gigabit Network} which ensure a low latency and a minimal noise. \\
The simulation's execution has been adapted to the parallel paradigm using many \textit{DMA} architecture configurations, each containing a certain number of nodes that apply the same \textit{transition function} to their own portion of cellular space. The configurations are namely made of 2, 4, 8 and 16 nodes of the same \textit{cluster}, running at the same time. As said before, the considered subdivision of the cellular space is along only one dimension and in portions of the same size. The cellular space, in simulated terms, is composed of a grid of square \textit{cells}, arranged in 610 columns and 496 rows. \\
With the intention of make the results of each test reliable, the considered timing values and all the related values inferred, like the speed-up quantity, are each the outcome of repeated executions of the same configuration whom outcomes are used to estimate an average value. This average value is then considered as a referential quantity starting from which all the consideration concerning a configuration are made.
\section{\textit{Sciddica T}}
With the aim of underlining how the field of the \textit{computational science} has inspired this work, it has been chosen to use, as test case for the conceived algorithm, a \textit{Cellular Automaton} model named \textit{Sciddica T}.\\
\textit{Sciddica}, acronym of \textit{\textbf{S}imulation through \textbf{C}omputational \textbf{I}nnovative methods for the \textbf{D}etection of \textbf{D}ebris flow path using \textbf{I}nteractive \textbf{C}ellular \textbf{A}utomata}, is a computational model designed to simulate a debris flow running along a hillside and is being used over the years to replicate and study several real cases. Among the several implementations of this model, the one to whom our tests make reference was 
designed to study the landslide phenomena 
of Tessina (Italy) occurred in the 1992,
 thus this particular version of the
 model is named \textit{Sciddica T}. 
 This \textit{CA} models as just said a debris flow, therefore the topology of the region where the landslide evolves is defined at the beginning of the simulation through a text file in the \textit{ASC (Action Script Communication) } format, containing the altitude of each \textit{cell} in the simulated space. In addition to the dataset concerning the topology, the simulator must refer to another file, again in the \textit{ASC} format, which contains the initial quantity of debris in each \textit{cell} in the hotbed of the landslide. The cellular space, as said before, is two-dimensional, with square \textit{cells} and obviously not toroidal. Each \textit{cell} evolves following a fixed \textit{transition function} which takes as input the internal state of the \textit{cells} into the \textit{Neighborhood}, supposed to be of the Von Neumann type with radius equal to 1. \\
 \begin{figure}[ht!]
\centering
    \includegraphics[width=0.75\textwidth]{early_state}
    \caption{Visual representation of the \textit{CA} in the first steps. The source of the landslide in red. The subdivision over 8 nodes ,of the cellular space shown by the white grid.}
\end{figure}
 Having said this, it is now necessary to explain the evolution of the \textit{CA} starting from its initial state. The \textit{SciddicaT} model is defined as a tuple of several values:
 \begin{equation}
 \label{sciddicaDef}
 SciddicaT = <R,X,Q,P,\sigma>
 \end{equation}
The values appearing in the equation \ref{sciddicaDef} are defined as follows :
\begin{itemize}
\item
\textbf{R} (Region), is the set of \textit{cells} which define the cellular space wherein the phenomenon evolves. Each \textit{cell} in \textit{R} is defined by a couple of integer coordinates \textit{(i,j)} respectively representing the position along the \textit{y-axis} and along the \textit{x-axis}.
\item
\textbf{X}, is the \textit{neighborhood} relation of the Von Neumann type, expressible with a vector \textit{(k,h)}. This vector belongs to the set of cardinality equal to 5 :\\
\begin{center}
\textit{N}=\Big\{ (0,0), (1,0), (-1,0), (0,1), (0,-1)\Big\}
\end{center}
When the vector \textit{(k,h)} is applied to the coordinates \textit{(i,j)} of a particular \textit{cell}, the result is a couple of integers representing the coordinates of the neighbor \textit{cell}. One must note that in the set \textit{N} is also contained a vector with both coordinates equal to zero, thus a \textit{cell} in this model is neighbor even of itself.
\item
\textbf{Q} (Quanta \cite{4} ), is the set of possible states that a \textit{cell} could assume. Each state is a tuple of 6 elements: 
\begin{center}
$q=(q_z,q_h,q_{\phi0},q_{\phi1},q_{\phi2},q_{\phi3})$
\end{center}
Every possible combination of this elements is the result of the Cartesian product of the 6 sub-states\\ 
that characterize a \textit{cell} :
\begin{itemize}
\item
$Q_h$ defines the quantity of debris contained in the \textit{cell}.
\item
$Q_z$ defines the topologic altitude of the \textit{cell}. This value is defined in the aforementioned configuration file and doesn't change during the simulation evolution. 
\item
$Q_{0..3}$ each of this values specifies the quantity of debris flowing out of the \textit{cell}, respectively in the direction of the neighboring \textit{cells}(barring itself).
\end{itemize}
\begin{center}
$ Q =Q_z \bigtimes Q_h \bigtimes Q_{0..3}$
\end{center}
\item
\textbf{P} is a set of constant parameters regulating the dynamic of the flows in the model. Namely there are two parameters :
\begin{itemize}
\item
\textit{$P_\epsilon$}  defines the minimum amount of debris under which nothing comes out of the \textit{cell}
\item
\textit{$P_r$}  is the parameter regulating the flow relaxation rate, that's to say how the strength of a flow decreases while crosses the \textit{cell} considered
\end{itemize}
\item
\bolden{$\sigma: Q \rightarrow Q $ }  is an application, between the states set and itself, called \textit{Transition function}. The \textit{transition function} as said before makes a \textit{cell} evolve considering the state of the \textit{neighborhood}. In this case, the function is made of two elementary components :
\begin{itemize}
\item \bolden{$\sigma_1$ } Considering the parameter $P_\epsilon$, the function determines if the quantity of debris in the \textit{cell} is enough to generate a flow, if successful the function computes the flows along the four directions and in the end, according to the parameter $P_r$, a new value for the flow strength is computed.
\item \bolden{$\sigma_2 : Q_h \rightarrow Q_h$ }  Determines a new value for the quantity of debris in the \textit{cell} which affect the result of the function $\sigma_1$.
\end{itemize}
\end{itemize}

 \begin{figure}[ht!]
\centering
    \includegraphics[trim=0mm 10mm 0mm 10mm,width=0.75\textwidth]{middle_state}
    \caption{\textit{SciddicaT} distributed over 8 nodes, mono-dimensional split, at step 4000}
\end{figure}

%2 Rows between figures
The model explained and the input data set provided have been modified, if 
compared to the original model inspired to the Tessina phenomenon, in order to 
%%%%%%%%%%%%%

 \begin{figure}[ht!]
\centering
	\vspace{13pt}
    \includegraphics[trim=0mm 10mm 0mm 10mm,width=0.75\textwidth]{late_state}
    \caption{\textit{SciddicaT} distributed over 8nodes, mono-dimensional split, at step 8000}
\end{figure}

\newpage
exploit all the nodes available and equally distribute the work load. Moreover, with the same aim, it has been evaluated that the propagation of the landslide over almost all the cellular space, and the subsequent activation of all the nodes available, requires circa 4000 steps. If then one considers that the transition function $\sigma$ is made of two distinct components, could model the simulation so that, rather than computing two components of the \textit{transition function} in the same step, the simulator doubles the number of steps, which become 8000, and than executes the component $\sigma_1$ of the \textit{transition function} during the even steps and the component $\sigma_2$ during the odd steps.
\section{Benchmarks}
The \textit{Lookahead} module of the \textit{vinoAC} framework has been implemented for the purpose of reducing the overhead of a \textit{CA} parallelization. Since the main cause of this overhead is the \textit{borders} exchange between adjacent Lps, during the design phase of the algorithm it has been decided to find a way to reduce exactly this phenomenon. Thanks to the techniques studied in \textit{distributed discrete-event simulations} literature, such reduction of \textit{borders} exchange become possible. In the case of the example model, the benefits of this overhead reduction approach appear particularly useful and appropriate as well. In a model like \textit{SciddicaT} in fact, where the computation is initially concentrated restricted region of the cellular space and are necessary several steps to make it extend to almost all the topology, a strategy like this could be beneficial because a part of the nodes in the simulation have a minor load of work and could be therefore potentially used as support in the execution of more massive tasks, assigned to other nodes.
\begin{table}[h!]
\centering
\label{bordersTable}
\begin{tabular}{ |p{4.5cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
&\multicolumn{4}{|c|}{Nodes} \\
\hline
&2 & 4 & 8 & 16 \\
\hline
Lp A (often busy) & 2451&9984&15694&15920\\
\hline
Lp B (moderately busy) & /&2294&2303&5816\\
\hline
Lp C (often idle) & 4&4&4&4\\

\hline
Avoided \% over 16000 & 84-99\%&37-85-99\%&3-85-99\%&3-63-99\%\\

\hline
\end{tabular}
\caption{Borders sent}
\end{table}

As one can say looking at the above table, in every simulation tested, the great majority of the Lps has significantly reduced the number of \textit{borders} sent to its adjacent nodes during the execution, meaning that, using the classic approach, it would have performed in vain a great portion of the 16000 \textit{borders} transmissions, that would be necessary to update the two adjacent Lp, resulting from a mono-dimensional cut, for all the 8000 steps scheduled. There is moreover, in every test run, at least one Lp which doesn't need to send not even one of it's \textit{borders} during the entire length of the simulation. This situation occurs particularly for those Lps which are delegated to make evolve the most marginal portions of the cellular space. In sum, for the Lps in this test case, it has been estimated that they have an inactivity percentage varying from the average value of 40\% to the extreme case of a 99\% inactivity.\\
This aspect, as planned, has clearly an impact in the reduction of the parallelization overhead and it can be noticed in first place, 
considering the course of the speed-up curve for the basic approach compared to the approach depicted in this report. 
It is important to underline, however, how each speed-up value considered 
in this case is equal to the mathematical ratio between the latency of an approach in its sequential
version and the latency of the same approach executed in the different parallel configurations.
It is also worth saying that the latency of a computation is defined as the ratio between the time elapsed 
to perform a certain work load and the work load itself and moreover this latter value is the reciprocal of the execution speed. 

 \begin{figure}[ht!]
\label{chart1}
\centering
	\vspace{13pt}
    \includegraphics[trim=0mm 10mm 0mm 10mm, width=0.75\textwidth]{time_elapsed}
    \caption{Average time elapsed for the various testing configurations}
\end{figure}

 \begin{figure}[ht!]
\label{chart2}
\centering
	\vspace{13pt}
    \includegraphics[trim=0mm 10mm 0mm 10mm, width=0.75\textwidth]{speedup_one}
    \caption{Speedup, in comparison of the their sequential version, for the basic algorithm and the \textit{lookahead} module}
\end{figure}

From a quick examination of the chart concerning the speedup evaluation, 
illustrated in the figure above, it is clear how 
the lookahead approach case maintains its speed-up more constant compared to the basic 
version of the \textit{CA} execution. Moreover the approach turns out to be more scalable, 
which is a desirable property in the context of a \textit{DMA}. \\

For the sake of clarity, the scalability is the property of a system that indicates its capability of 
handling the growth of the work load by simply adding computational nodes to the architecture. 
This property is therefore obviously related to the overhead issue, so what we have just 
explained in relation to the chart and the \textit{lookahead} approach, matches exactly the 
conclusions one could infer studying the chart from the point of view of the scalability, that's 
to say the more the system is scalable the less overhead came up from the parallelization.   \\

 \begin{figure}[ht!]
\label{chart3}
\centering
	\vspace{13pt}
    \includegraphics[trim=0mm 10mm 0mm 10mm, width=0.75\textwidth]{latency}
    \caption{The values of latency for the considered approaches}
\end{figure}

Another important quantity that can emphasize the reduction of overhead is the aforementioned latency. Since it is defined as the quotient of the work load over the time elapsed to perform it, and since the work load for each node is equally assigned and decreasing at the growth of the whole number of nodes in the simulation, while processing the results of the tests we're discussing, it seemed appropriate to evaluate the latency of each test configuration as the mathematical product of the average time elapsed for each node execution, and the number of nodes employed. The chart highlights in first place the difference in growth rate between the two approaches' curves. The curve concerning the basic algorithm grows quickly on the contrary of the curve related to the algorithm using the \textit{lookahead}, which tends to stay constant. This aspect underlines again the great scalability of the designed approach because of its minimal overhead. Secondly and more trivially, the chart shows the better performances, applied to the various configurations of the cluster, of the \textit{lookahead} approach compared to the old mechanism. \\

One last measurement performed in this testing phase is about the evaluation of the speedup related to the \textit{lookahead} module as opposed the basic version. Unlike the preceding speedup definition, in this case this quantity is computed as the mathematical ratio between the latency of the old approach and the new approach, considering the same number of nodes available. The results, illustrated in the chart below, show a curve growing together with the number of nodes used, and makes evident the advantages of using the approach explained in this thesis.

 \begin{figure}[ht!]
\label{chart3}
\centering
	\vspace{13pt}
    \includegraphics[trim=0mm 10mm 0mm 10mm, width=0.75\textwidth]{speedup_two}
    \caption{Speed-up of the basic approach over the \textit{Lookahead} module}
\end{figure}

\newpage
\chapter{Possible future extensions and conclusions}

\section{Recapitulation of the work}
The discussion presented in this report originates from the study of the simulation systems and their application to the field of \textit{Computational Science}. In particular, we have focused on a discrete, time-stepped paradigm called \textit{Cellular Automata}. Since in the majority of the simulation systems, the main aim is to reduce the execution time of the model, a \textit{CA} execution is often distributed on parallel architectures. Among the various possible architectures, the one considered in this work, for its general validity, is a \textit{Distributed Machine Architecture (DMA)}, that's to say a collection of different processors each with its own memory space. The execution is split between various \textit{Logical Processes (Lp)}, each parallel executing its portion of simulation. However at some points in the \textit{wallclock time} an information exchange between processes is inevitable in order to make evolve the simulation as a whole.\\
 For this purpose it was chosen to use the \textit{Message Passing Interface (MPI)} technology, that is a language independent \textit{API} with various implementations. In the light of the efficiency intent of this systems, the obvious choice among the programming languages presenting one or more implementation, was \textit{C++} on account of its performance, robustness and its orientation to the \textit{Object Oriented Programming (OOP)}. The \textit{MPI} paradigm has been chosen for its portability but also its non-blocking methods which allow better timings for the executions. The cited exchange of informations causes a time overhead coming from the parallelization. It's in fact necessary, when a \textit{CA}'s execution is distributed over multiple Lps, splitting the cellular space, a regular interchange of the informations concerning the \textit{Cells} on the \textit{Borders} of a portion of space. Thus, to reduce this overhead, it has been tried to apply general techniques of \textit{Distributed discrete-event simulation (DES)} to the \textit{CA} case. 
 
 \section{Simplifications and more effective approaches}
 
 One interesting concept that appears in the literature of this techniques, is the notion of \textit{LookAhead}. This value is defined as a non-negative integer, representing the minimum number of steps, in our case, first of whom an Lp is sure of not receiving any information coming from a neighbor process. Thanks to this data, dynamically computed during the execution, it was possible to come out with a \textit{conservative} mechanism, simpler but less effective to increment the performance, to avoid the \textit{Borders} exchange whenever possible, instead of banally communicate these informations sight unseen, after each step.\\
 It is clear that the selection of a non-conservative approach, instead of a conservative one, would hopefully lead to better timings under favorable conditions. With this purpose, one could therefore design a rollback mechanism for the cellular space, after it has came through the \textit{Transition Function}, maybe by combining the several techniques explained in the literature, and then set up the simulation to adopt an optimistic approach. An Lp then wouldn't provide for the \textit{Borders} exchange with all the neighboring Lps, but optimistically would apply the \textit{Transition Function} to its \textit{Cells}, step after step. However it should then roll back its execution whenever a consistency error is detected in order to communicate the missing informations that corrupted the execution, thus recovering the evolution of the simulation. Anyway, in order to be able of applying such mechanism, it is necessary to ponder the way the roll-back operation is performed, evaluating its impact in terms of spacial and time complexity. Additionally the preference of a non-conservative approach, should be driven by a statistical study of the application background. It's necessary in fact to understand statistically if and when it is possible to avoid the communication of a \textit{Border} and then evaluate the gain which could result even from the best case, versus the timings of the application of a conservative algorithm to the same instance of the problem. \\
 In spite of the usage of the \textit{LookAhead} notion, the latter could acquire other meanings and other purposes within an algorithm. For instance this value could be associated to each \textit{Cell} into the cellular space, as the representation of the number of steps first of whom the state of the \textit{Cell} won't change for sure. Knowing this data about a \textit{Cell}, while applying the \textit{Transition Function}, an Lp can avoid the computation for all those spacial units with a \textit{LookAhead} value, with this last sense,  greater than zero, but rather only decrementing this quantity. Such computation avoidance could lead to sure gain of performance as the increase of the \textit{Idle Cells} and the dimension of the cellular space. On this occasion, the main problem is to evaluate in a reasonable time a \textit{LookAhead} value for each \textit{Cell}, when needed.\\
 One last simplification made during the implementation phase of this work, has been the choice of splitting the cellular space only along one dimension at time. Even if this decision doesn't heavily affect the parallelization of a \textit{CA}, it surely is a restriction which stops the modeler from pushing to the limit the division of the cellular space, which potentially could be distributed even to a number of Lps equal to the number of \textit{Cells} in the simulated space, although this choice would be meaningless. On the other hand a multi-dimensional split of the cellular space could led, also in this case, to a gain in performance, if the subdivision is driven by the consideration of the issues that could result from the overhead of a parallelization gone too far. Furthermore such split could lead to issues related to the complex shape of resulting \textit{Borders}. For instance, as in the mechanism explained in this work, a two-dimensional split of a cellular space with square \textit{Cells}, generates an adjacency relation between Lps which share \textit{Borders} located in the corner of their respective space portions. Such kind of \textit{Border} could entail issues when an Lp needs to compute the distance between an active \textit{Cell} and that \textit{Border}.
 \section{Closing remarks}
 The mechanism illustrated in this report tries to implement a method of parallelization of a \textit{CA}, in order to make its execution faster and therefore the simulations, performed using a framework which implements the explained module, more effective. In this thesis in fact, it has been pointed out many times the importance of a simulation execution as fast as possible. An example is the simulation of a natural process to prevent its effects, or maybe a simulator which has to perform real-time computations in order to produce immediate solutions for a certain problem, like a simulator which solves the assignment of the airplanes to landing strips in an airport. For each one of these situations the speed of the system is very important, not only to guarantee a good experience to the user of the software, but also to assist an human in the act of avoiding or reducing damages to things and persons, potentially resulting from such situations.
\addcontentsline{toc}{chapter}{Bibliography} 
\nocite{0}
\nocite{1}
\nocite{2}
\nocite{3}
\nocite{4}
\printbibliography{}
\end{document}
